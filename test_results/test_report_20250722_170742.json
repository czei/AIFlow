{
  "summary": {
    "total": 5,
    "passed": 2,
    "failed": 3,
    "success_rate": "40.0%",
    "total_duration": "12.84s",
    "timestamp": "2025-07-22T21:07:42.533376+00:00"
  },
  "by_layer": {
    "shell": {
      "total": 5,
      "passed": 2,
      "failed": 3
    }
  },
  "results": [
    {
      "name": "analyze_logs.sh",
      "success": false,
      "duration": "0.00s",
      "timestamp": "2025-07-22T21:07:29.698344+00:00",
      "metadata": {
        "exit_code": 1,
        "script_path": "analyze_logs.sh",
        "layer": "shell"
      },
      "error": "\u274c Logs directory not found: ./.logs\nRun some automation first to generate logs.\n"
    },
    {
      "name": "install.sh",
      "success": true,
      "duration": "0.01s",
      "timestamp": "2025-07-22T21:07:29.704092+00:00",
      "metadata": {
        "exit_code": 0,
        "script_path": "install.sh",
        "layer": "shell"
      },
      "error": "\ud83d\ude80 Installing Claude Code Project Management Commands...\n\u2705 Commands installed successfully!\n\nAvailable commands:\n  /user:project:setup <project-name>    - Create new project worktree and structure\n  /user:project:doctor                  - Validate project setup\n  /user:project:start                   - Begin automated development\n  /user:project:status                  - Show project progress\n  /user:project:pause                   - Pause automation\n  /user:project:resume                  - Resume automation\n  /user:project:stop                    - End project cleanly\n  /user:project:advance [phase]         - Force phase advancement\n  /user:project:phase <action>          - Manage phases\n\nNext steps:\n1. Navigate to a git repository\n2. Run: /user:project:setup my-project-name\n3. Customize the phase files created\n4. Run: /user:project:doctor\n5. Run: /user:project:start\n\nNote: These commands are designed for use with --dangerously-skip-permissions\nEnsure you understand the risks and operate in isolated git worktrees.\n\ncp: /Users/czei/claude-project-commands/project/*: No such file or directory\n"
    },
    {
      "name": "tests/integration_test.sh",
      "success": true,
      "duration": "6.33s",
      "timestamp": "2025-07-22T21:07:36.034365+00:00",
      "metadata": {
        "exit_code": 0,
        "script_path": "tests/integration_test.sh",
        "layer": "shell"
      },
      "error": "\ud83e\uddea Phase-Driven Development System Integration Test\n==================================================\n\n\u001b[1;33m\u2139\ufe0f  Setting up test environment...\u001b[0m\nInitialized empty Git repository in /Users/czei/ai-software-project-management/test-output/test-repo/.git/\n[main (root-commit) e732683] Initial commit\n 1 file changed, 1 insertion(+)\n create mode 100644 README.md\n\u001b[0;32m\u2705 Test environment ready\u001b[0m\n\nTest 1: Project Setup\n--------------------\n\u001b[1;33m\u2139\ufe0f  Creating git worktree...\u001b[0m\nHEAD is now at e732683 Initial commit\n\u001b[0;32m\u2705 Git worktree created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Creating project structure...\u001b[0m\n\u001b[0;32m\u2705 Project structure created\u001b[0m\n\nTest 2: Phase Execution\n----------------------\n\u001b[1;33m\u2139\ufe0f  Executing Phase 01: Setup...\u001b[0m\n\u001b[0;32m\u2705 Phase 01 outputs created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Executing Phase 02: Process...\u001b[0m\n\u001b[0;32m\u2705 Phase 02 outputs created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Executing Phase 03: Validate...\u001b[0m\n\u001b[0;32m\u2705 Phase 03 validation complete\u001b[0m\n\nTest 3: State Management\n-----------------------\n\u001b[1;33m\u2139\ufe0f  Testing workflow state transitions...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 1: planning\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 2: implementation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 3: validation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 4: review\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 5: refinement\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 6: integration\u001b[0m\n\u001b[0;32m\u2705 Workflow state transitions tested\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Testing quality gate tracking...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: compilation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: testing\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: review\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: integration\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: documentation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: performance\u001b[0m\n\u001b[0;32m\u2705 Quality gates tracked successfully\u001b[0m\n\nTest 4: Logging Infrastructure\n-----------------------------\n\u001b[1;33m\u2139\ufe0f  Creating structured logs...\u001b[0m\n\u001b[0;32m\u2705 Structured logs created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Testing log analysis...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Total log entries:        7\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Correlated events: .logs/automation.log:2\n.logs/commands.log:2\n.logs/performance.log:0\n.logs/quality-gates.log:0\u001b[0m\n\u001b[0;32m\u2705 Logging infrastructure verified\u001b[0m\n\nTest 5: Measurable Outcomes\n--------------------------\n\u001b[1;33m\u2139\ufe0f  Verifying all measurable outcomes...\u001b[0m\n\u001b[0;32m\u2705 File exists: output/setup.txt\u001b[0m\n\u001b[0;32m\u2705 File exists: output/config.json\u001b[0m\n\u001b[0;32m\u2705 File exists: output/metrics.json\u001b[0m\n\u001b[0;32m\u2705 File exists: output/processed_data.csv\u001b[0m\n\u001b[0;32m\u2705 File exists: output/validation_report.txt\u001b[0m\n\u001b[0;32m\u2705 File exists: .project-state.json\u001b[0m\n\u001b[0;32m\u2705 File exists: .workflow-state.json\u001b[0m\n\u001b[0;32m\u2705 All expected files created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Checking measurable changes...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  setup.txt has        3 lines\u001b[0m\n\u001b[0;32m\u2705 config.json is valid JSON\u001b[0m\n\u001b[1;33m\u2139\ufe0f  CSV has        4 lines\u001b[0m\n\u001b[0;32m\u2705 Test summary created\u001b[0m\n\n==================================================\n\u001b[0;32m\u2705 All integration tests completed successfully! \ud83c\udf89\u001b[0m\n\n\u001b[1;33m\u2139\ufe0f  Test artifacts available at: /Users/czei/ai-software-project-management/test-output/test-measurable-project\u001b[0m\n\n\n\u001b[1;33m\u2139\ufe0f  Cleaning up...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Cleaning up test directory...\u001b[0m\n\nPreparing worktree (new branch 'feature/test-measurable-project')\n"
    },
    {
      "name": "tests/run_all_tests.sh",
      "success": false,
      "duration": "6.39s",
      "timestamp": "2025-07-22T21:07:42.421462+00:00",
      "metadata": {
        "exit_code": 1,
        "script_path": "tests/run_all_tests.sh",
        "layer": "shell"
      },
      "error": "\ud83e\uddea Phase-Driven Development System - Full Test Suite\n===================================================\n\n\n\u001b[1;33mRunning: Unit Tests\u001b[0m\n----------------------------------------\n\u001b[0;32m\u2705 Unit Tests passed\u001b[0m\n\n\u001b[1;33mRunning: Command Flow Test\u001b[0m\n----------------------------------------\n\ud83e\uddea Claude Code Command Flow Test\n================================\n\n\n--- Executing: /user:project:setup test-project ---\n\ud83d\udd27 Setting up project: test-project\n\u2705 Project structure created at: /Users/czei/ai-software-project-management/test-output/command-test/test-project\n\n--- Executing: /user:project:doctor  ---\n\ud83d\udd0d Running project doctor...\n\u2705 Project structure\n\u2705 State file\n\u2705 Phase files\n\u2705 Output directory\n\u2705 Logs directory\n\n\u2705 All checks passed! Ready to start.\n\n--- Executing: /user:project:start  ---\n\ud83d\ude80 Starting automated development...\n\u2705 Automation started\n\ud83d\udccd Beginning Phase 01...\n\u2705 Phase 01 outputs created\n\n--- Executing: /user:project:status  ---\n\ud83d\udcca Project Status\n================\nProject: test-project\nStatus: active\nCurrent Phase: 01\nWorkflow Step: planning\nAutomation: ACTIVE\nCompleted Phases: None\n\nOutputs Created: 2\n  - phase01.txt\n  - progress.json\n\n--- Executing: /user:project:pause  ---\n\u23f8\ufe0f  Pausing automation...\n\u2705 Automation paused\n\n--- Executing: /user:project:status  ---\n\ud83d\udcca Project Status\n================\nProject: test-project\nStatus: active\nCurrent Phase: 01\nWorkflow Step: planning\nAutomation: PAUSED\nCompleted Phases: None\n\nOutputs Created: 2\n  - phase01.txt\n  - progress.json\n\n--- Executing: /user:project:resume  ---\n\u25b6\ufe0f  Resuming automation...\n\u2705 Automation resumed\n\n--- Executing: /user:project:update  ---\n\ud83d\udcdd Updating project state...\n\u2705 Updated workflow step to: implementation\n\n--- Executing: /user:project:advance  ---\n\u23ed\ufe0f  Advancing phase...\n\u2705 Advanced from Phase 01 to Phase 02\n\u2705 Phase 02 outputs created\n\n--- Executing: /user:project:status  ---\n\ud83d\udcca Project Status\n================\nProject: test-project\nStatus: active\nCurrent Phase: 02\nWorkflow Step: planning\nAutomation: ACTIVE\nCompleted Phases: 01\n\nOutputs Created: 3\n  - phase01.txt\n  - phase02.txt\n  - progress.json\n\n--- Executing: /user:project:stop  ---\n\ud83c\udfc1 Stopping project...\n\n\ud83d\udcca Project Summary:\n  - Phases Completed: 1\n  - Files Created: 3\n  - Status: COMPLETED\n\n\u2705 Command flow test completed!\nTest artifacts at: /Users/czei/ai-software-project-management/test-output/command-test\n\nClean up test directory? (y/n): \u001b[0;31m\u274c Command Flow Test failed\u001b[0m\n\n\u001b[1;33mRunning: Integration Test\u001b[0m\n----------------------------------------\n\ud83e\uddea Phase-Driven Development System Integration Test\n==================================================\n\n\u001b[1;33m\u2139\ufe0f  Setting up test environment...\u001b[0m\nInitialized empty Git repository in /Users/czei/ai-software-project-management/test-output/test-repo/.git/\n[main (root-commit) ee9f4cb] Initial commit\n 1 file changed, 1 insertion(+)\n create mode 100644 README.md\n\u001b[0;32m\u2705 Test environment ready\u001b[0m\n\nTest 1: Project Setup\n--------------------\n\u001b[1;33m\u2139\ufe0f  Creating git worktree...\u001b[0m\nHEAD is now at ee9f4cb Initial commit\n\u001b[0;32m\u2705 Git worktree created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Creating project structure...\u001b[0m\n\u001b[0;32m\u2705 Project structure created\u001b[0m\n\nTest 2: Phase Execution\n----------------------\n\u001b[1;33m\u2139\ufe0f  Executing Phase 01: Setup...\u001b[0m\n\u001b[0;32m\u2705 Phase 01 outputs created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Executing Phase 02: Process...\u001b[0m\n\u001b[0;32m\u2705 Phase 02 outputs created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Executing Phase 03: Validate...\u001b[0m\n\u001b[0;32m\u2705 Phase 03 validation complete\u001b[0m\n\nTest 3: State Management\n-----------------------\n\u001b[1;33m\u2139\ufe0f  Testing workflow state transitions...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 1: planning\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 2: implementation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 3: validation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 4: review\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 5: refinement\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Workflow step 6: integration\u001b[0m\n\u001b[0;32m\u2705 Workflow state transitions tested\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Testing quality gate tracking...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: compilation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: testing\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: review\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: integration\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: documentation\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Quality gate passed: performance\u001b[0m\n\u001b[0;32m\u2705 Quality gates tracked successfully\u001b[0m\n\nTest 4: Logging Infrastructure\n-----------------------------\n\u001b[1;33m\u2139\ufe0f  Creating structured logs...\u001b[0m\n\u001b[0;32m\u2705 Structured logs created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Testing log analysis...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Total log entries:        7\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Correlated events: .logs/automation.log:2\n.logs/commands.log:2\n.logs/performance.log:0\n.logs/quality-gates.log:0\u001b[0m\n\u001b[0;32m\u2705 Logging infrastructure verified\u001b[0m\n\nTest 5: Measurable Outcomes\n--------------------------\n\u001b[1;33m\u2139\ufe0f  Verifying all measurable outcomes...\u001b[0m\n\u001b[0;32m\u2705 File exists: output/setup.txt\u001b[0m\n\u001b[0;32m\u2705 File exists: output/config.json\u001b[0m\n\u001b[0;32m\u2705 File exists: output/metrics.json\u001b[0m\n\u001b[0;32m\u2705 File exists: output/processed_data.csv\u001b[0m\n\u001b[0;32m\u2705 File exists: output/validation_report.txt\u001b[0m\n\u001b[0;32m\u2705 File exists: .project-state.json\u001b[0m\n\u001b[0;32m\u2705 File exists: .workflow-state.json\u001b[0m\n\u001b[0;32m\u2705 All expected files created\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Checking measurable changes...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  setup.txt has        3 lines\u001b[0m\n\u001b[0;32m\u2705 config.json is valid JSON\u001b[0m\n\u001b[1;33m\u2139\ufe0f  CSV has        4 lines\u001b[0m\n\u001b[0;32m\u2705 Test summary created\u001b[0m\n\n==================================================\n\u001b[0;32m\u2705 All integration tests completed successfully! \ud83c\udf89\u001b[0m\n\n\u001b[1;33m\u2139\ufe0f  Test artifacts available at: /Users/czei/ai-software-project-management/test-output/test-measurable-project\u001b[0m\n\n\n\u001b[1;33m\u2139\ufe0f  Cleaning up...\u001b[0m\n\u001b[1;33m\u2139\ufe0f  Cleaning up test directory...\u001b[0m\n\u001b[0;32m\u2705 Integration Test passed\u001b[0m\n\n===================================================\nTest Summary:\n  \u001b[0;32mPassed: 2\u001b[0m\n  \u001b[0;31mFailed: 1\u001b[0m\n\n\u001b[0;31m\u274c Some tests failed\u001b[0m\n\ntest_log_file_creation (__main__.TestLoggingInfrastructure.test_log_file_creation)\nTest that all log files are created ... ok\ntest_performance_metrics (__main__.TestLoggingInfrastructure.test_performance_metrics)\nTest performance logging ... /Users/czei/ai-software-project-management/tests/test_phases.py:524: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\nok\ntest_structured_logging (__main__.TestLoggingInfrastructure.test_structured_logging)\nTest JSON structured log format ... /Users/czei/ai-software-project-management/tests/test_phases.py:493: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\nok\ntest_automation_control (__main__.TestPhaseDrivenDevelopment.test_automation_control)\nTest automation pause/resume functionality ... /Users/czei/ai-software-project-management/tests/test_phases.py:181: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"started\": datetime.utcnow().isoformat() + \"Z\"\nok\ntest_error_recovery (__main__.TestPhaseDrivenDevelopment.test_error_recovery)\nTest error handling and recovery ... ok\ntest_phase_advancement (__main__.TestPhaseDrivenDevelopment.test_phase_advancement)\nTest phase progression logic ... ok\ntest_phase_file_structure (__main__.TestPhaseDrivenDevelopment.test_phase_file_structure)\nTest that phase files have required sections ... ok\ntest_phase_operations (__main__.TestPhaseDrivenDevelopment.test_phase_operations)\nTest actual phase operations (file creation/modification) ... /Users/czei/ai-software-project-management/tests/test_phases.py:311: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  initial_data = {\"version\": \"1.0\", \"created\": datetime.utcnow().isoformat()}\n/Users/czei/ai-software-project-management/tests/test_phases.py:313: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  log_file.write_text(f\"[{datetime.utcnow().isoformat()}] Project initialized\\n\")\n/Users/czei/ai-software-project-management/tests/test_phases.py:328: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  f.write(f\"[{datetime.utcnow().isoformat()}] Processing started\\n\")\n/Users/czei/ai-software-project-management/tests/test_phases.py:342: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  Generated: {datetime.utcnow().isoformat()}\n/Users/czei/ai-software-project-management/tests/test_phases.py:369: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"completed\": datetime.utcnow().isoformat()\nok\ntest_quality_gates (__main__.TestPhaseDrivenDevelopment.test_quality_gates)\nTest quality gate tracking ... ok\ntest_state_management (__main__.TestPhaseDrivenDevelopment.test_state_management)\nTest project state file operations ... ok\ntest_workflow_progression (__main__.TestPhaseDrivenDevelopment.test_workflow_progression)\nTest 6-step workflow state transitions ... ok\n\n----------------------------------------------------------------------\nRan 11 tests in 0.012s\n\nOK\n/Users/czei/ai-software-project-management/tests/test_command_flow.py:77: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"started\": datetime.utcnow().isoformat() + \"Z\"\n/Users/czei/ai-software-project-management/tests/test_command_flow.py:304: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  phase_file.write_text(f\"Phase {phase_num} executed at {datetime.utcnow().isoformat()}\\n\")\n/Users/czei/ai-software-project-management/tests/test_command_flow.py:314: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"completed\": datetime.utcnow().isoformat(),\n/Users/czei/ai-software-project-management/tests/test_command_flow.py:283: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  state[\"completed\"] = datetime.utcnow().isoformat() + \"Z\"\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/test_command_flow.py\", line 369, in <module>\n    main()\n    ~~~~^^\n  File \"/Users/czei/ai-software-project-management/tests/test_command_flow.py\", line 361, in main\n    response = input(\"\\nClean up test directory? (y/n): \")\nEOFError: EOF when reading a line\nPreparing worktree (new branch 'feature/test-measurable-project')\n"
    },
    {
      "name": "tests/run_unit_tests.sh",
      "success": false,
      "duration": "0.11s",
      "timestamp": "2025-07-22T21:07:42.533269+00:00",
      "metadata": {
        "exit_code": 1,
        "script_path": "tests/run_unit_tests.sh",
        "layer": "shell"
      },
      "error": "Running unit tests for deterministic components...\n================================================\n\n\u274c Unit tests failed with exit code: 1\n\ntest_log_event_console_output (test_basic_logger.TestBasicLogger.test_log_event_console_output)\nTest log event prints to console ... /Users/czei/ai-software-project-management/logged_secure_shell.py:59: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\nok\ntest_log_event_invalid_json_state (test_basic_logger.TestBasicLogger.test_log_event_invalid_json_state)\nTest log event handles invalid JSON in state file ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"test-uuid-1234\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\n[INFO] automation: test_event\nok\ntest_log_event_missing_state_file (test_basic_logger.TestBasicLogger.test_log_event_missing_state_file)\nTest log event handles missing state file gracefully ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"test-uuid-1234\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\n[INFO] automation: test_event\nERROR\ntest_log_event_structure (test_basic_logger.TestBasicLogger.test_log_event_structure)\nTest log event creates proper JSON structure ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"test-uuid-1234\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\n[INFO] automation: test_event - {\"key\":\"value\"}\nok\ntest_log_event_unknown_category (test_basic_logger.TestBasicLogger.test_log_event_unknown_category)\nTest unknown category defaults to automation log ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"test-uuid-1234\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\n[INFO] unknown_category: test_event\nok\ntest_log_file_selection (test_basic_logger.TestBasicLogger.test_log_file_selection)\nTest correct log file is selected based on category ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"test-uuid-1234\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\n[INFO] automation: test_event\n[INFO] workflow: test_event\n[INFO] commands: test_event\n[INFO] errors: test_event\n[INFO] performance: test_event\nok\ntest_logger_auto_correlation_id (test_basic_logger.TestBasicLogger.test_logger_auto_correlation_id)\nTest logger generates correlation ID when not provided ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"test-uuid-1234\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\nok\ntest_logger_initialization (test_basic_logger.TestBasicLogger.test_logger_initialization)\nTest logger initializes with correct attributes ... [INFO] automation: logger_initialized - {\"project_dir\":\"/test/project\",\"correlation_id\":\"custom-id\",\"log_files_created\":[\"automation\",\"workflow\",\"commands\",\"quality-gates\",\"phase-transitions\",\"errors\",\"performance\"]}\nok\ntest_load_project_state_file_not_found (test_logged_secure_shell.TestLoggedSecureShell.test_load_project_state_file_not_found)\nTest project state loading when file not found ... ok\ntest_load_project_state_invalid_json (test_logged_secure_shell.TestLoggedSecureShell.test_load_project_state_invalid_json)\nTest project state loading with invalid JSON ... ok\ntest_load_project_state_success (test_logged_secure_shell.TestLoggedSecureShell.test_load_project_state_success)\nTest successful project state loading ... ok\ntest_shell_initialization (test_logged_secure_shell.TestLoggedSecureShell.test_shell_initialization)\nTest shell initializes with correct attributes ... ok\ntest_validate_command_phase_args_preview (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_args_preview)\nTest args preview in validation logging ... ok\ntest_validate_command_phase_implementation (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_implementation)\nTest command validation for implementation phase ... ok\ntest_validate_command_phase_performance_tracking (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_performance_tracking)\nTest that command validation tracks performance ... ok\ntest_validate_command_phase_planning (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_planning)\nTest command validation for planning phase ... ok\ntest_validate_command_phase_review (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_review)\nTest command validation for review phase ... ok\ntest_validate_command_phase_unknown (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_unknown)\nTest command validation for unknown phase ... ok\ntest_validate_command_phase_validation (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_validation)\nTest command validation for validation phase ... ok\ntest_validate_command_phase_validation_result (test_logged_secure_shell.TestLoggedSecureShell.test_validate_command_phase_validation_result)\nTest validation result logging ... ok\ntest_main_empty_command (test_logged_secure_shell.TestLoggedSecureShellCommandParsing.test_main_empty_command)\nTest main with empty command string ... \u274c Empty command provided\nok\ntest_main_invalid_command_string (test_logged_secure_shell.TestLoggedSecureShellCommandParsing.test_main_invalid_command_string)\nTest main with invalid command string ... \u274c Invalid command string: No closing quotation\nok\ntest_main_no_command (test_logged_secure_shell.TestLoggedSecureShellCommandParsing.test_main_no_command)\nTest main with no command provided ... Usage: logged_secure_shell <command>\nok\ntest_discover_tests (test_test_runner_v2.TestShellTestLayer.test_discover_tests)\nTest test discovery ... ok\ntest_discover_tests_multiple_patterns (test_test_runner_v2.TestShellTestLayer.test_discover_tests_multiple_patterns)\nTest discovery with multiple patterns ... ok\ntest_run_test_failure (test_test_runner_v2.TestShellTestLayer.test_run_test_failure)\nTest failed test execution ... ERROR\ntest_run_test_permission_error (test_test_runner_v2.TestShellTestLayer.test_run_test_permission_error)\nTest permission error handling ... FAIL\ntest_run_test_success (test_test_runner_v2.TestShellTestLayer.test_run_test_success)\nTest successful test execution ... FAIL\ntest_run_test_timeout (test_test_runner_v2.TestShellTestLayer.test_run_test_timeout)\nTest test execution timeout ... FAIL\ntest_run_test_with_input (test_test_runner_v2.TestShellTestLayer.test_run_test_with_input)\nTest that input=\"\" is passed to prevent hangs ... ERROR\ntest_context_defaults (test_test_runner_v2.TestTestContext.test_context_defaults)\nTest TestContext default values ... ok\ntest_context_initialization (test_test_runner_v2.TestTestContext.test_context_initialization)\nTest TestContext initializes correctly ... ok\ntest_get_layer (test_test_runner_v2.TestTestLayerRegistry.test_get_layer)\nTest getting registered layer ... ok\ntest_get_nonexistent_layer (test_test_runner_v2.TestTestLayerRegistry.test_get_nonexistent_layer)\nTest getting non-existent layer returns None ... ok\ntest_list_layers (test_test_runner_v2.TestTestLayerRegistry.test_list_layers)\nTest listing all layers ... ok\ntest_register_layer (test_test_runner_v2.TestTestLayerRegistry.test_register_layer)\nTest layer registration ... ok\ntest_result_initialization (test_test_runner_v2.TestTestResult.test_result_initialization)\nTest TestResult initializes correctly ... ok\ntest_result_to_dict (test_test_runner_v2.TestTestResult.test_result_to_dict)\nTest TestResult.to_dict method ... ok\ntest_calculate_summary (test_test_runner_v2.TestTestRunner.test_calculate_summary)\nTest summary calculation from results ... ERROR\ntest_initialization (test_test_runner_v2.TestTestRunner.test_initialization)\nTest runner initialization ... ERROR\ntest_load_config_missing (test_test_runner_v2.TestTestRunner.test_load_config_missing)\nTest config loading with missing file ... ERROR\ntest_load_config_success (test_test_runner_v2.TestTestRunner.test_load_config_success)\nTest successful config loading ... ERROR\ntest_run_layer_disabled (test_test_runner_v2.TestTestRunner.test_run_layer_disabled)\nTest running disabled layer ... ERROR\ntest_run_layer_success (test_test_runner_v2.TestTestRunner.test_run_layer_success)\nTest running enabled layer ... ERROR\ntest_save_results (test_test_runner_v2.TestTestRunner.test_save_results)\nTest saving results to JSON ... ERROR\n\n======================================================================\nERROR: test_log_event_missing_state_file (test_basic_logger.TestBasicLogger.test_log_event_missing_state_file)\nTest log event handles missing state file gracefully\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py\", line 1424, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_basic_logger.py\", line 167, in test_log_event_missing_state_file\n    written_data = write_calls[0][0][0]\n                   ~~~~~~~~~~~^^^\nIndexError: list index out of range\n\n======================================================================\nERROR: test_run_test_failure (test_test_runner_v2.TestShellTestLayer.test_run_test_failure)\nTest failed test execution\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py\", line 1424, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 168, in test_run_test_failure\n    self.assertEqual(result.metadata['exit_code'], 1)\n                     ~~~~~~~~~~~~~~~^^^^^^^^^^^^^\nKeyError: 'exit_code'\n\n======================================================================\nERROR: test_run_test_with_input (test_test_runner_v2.TestShellTestLayer.test_run_test_with_input)\nTest that input=\"\" is passed to prevent hangs\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py\", line 1424, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 202, in test_run_test_with_input\n    call_kwargs = mock_run.call_args[1]\n                  ~~~~~~~~~~~~~~~~~~^^^\nTypeError: 'NoneType' object is not subscriptable\n\n======================================================================\nERROR: test_calculate_summary (test_test_runner_v2.TestTestRunner.test_calculate_summary)\nTest summary calculation from results\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nERROR: test_initialization (test_test_runner_v2.TestTestRunner.test_initialization)\nTest runner initialization\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nERROR: test_load_config_missing (test_test_runner_v2.TestTestRunner.test_load_config_missing)\nTest config loading with missing file\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nERROR: test_load_config_success (test_test_runner_v2.TestTestRunner.test_load_config_success)\nTest successful config loading\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nERROR: test_run_layer_disabled (test_test_runner_v2.TestTestRunner.test_run_layer_disabled)\nTest running disabled layer\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nERROR: test_run_layer_success (test_test_runner_v2.TestTestRunner.test_run_layer_success)\nTest running enabled layer\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nERROR: test_save_results (test_test_runner_v2.TestTestRunner.test_save_results)\nTest saving results to JSON\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 251, in setUp\n    self.runner = TestRunner(project_root=\"/test/project\")\n                  ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/czei/ai-software-project-management/test_runner_v2.py\", line 242, in __init__\n    self.results_dir.mkdir(exist_ok=True)\n    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/pathlib/_local.py\", line 722, in mkdir\n    os.mkdir(self, mode)\n    ~~~~~~~~^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/test/project/test_results'\n\n======================================================================\nFAIL: test_run_test_permission_error (test_test_runner_v2.TestShellTestLayer.test_run_test_permission_error)\nTest permission error handling\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py\", line 1424, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 189, in test_run_test_permission_error\n    self.assertIn(\"Script not executable\", result.error)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: 'Script not executable' not found in 'Script not found: /test/project/test.sh'\n\n======================================================================\nFAIL: test_run_test_success (test_test_runner_v2.TestShellTestLayer.test_run_test_success)\nTest successful test execution\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py\", line 1424, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 145, in test_run_test_success\n    self.assertTrue(result.success)\n    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\nAssertionError: False is not true\n\n======================================================================\nFAIL: test_run_test_timeout (test_test_runner_v2.TestShellTestLayer.test_run_test_timeout)\nTest test execution timeout\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/unittest/mock.py\", line 1424, in patched\n    return func(*newargs, **newkeywargs)\n  File \"/Users/czei/ai-software-project-management/tests/unit/test_test_runner_v2.py\", line 179, in test_run_test_timeout\n    self.assertIn(\"Test timed out\", result.error)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: 'Test timed out' not found in 'Script not found: /test/project/test.sh'\n\n----------------------------------------------------------------------\nRan 45 tests in 0.020s\n\nFAILED (failures=3, errors=10)\n"
    }
  ]
}